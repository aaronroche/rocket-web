# Scaling Rocket Web
Purpose: This document details some options for scaling each component of Rocket Web to effectively meet growing demand, maintain performance, and ensure optimized resource utilization.

### EC2
- Based on CloudWatch dashboard and metrics, if we notice that our EC2 instance is not powerful enough to handle all the incoming request traffic, we can explore vertical or horizontal scaling options.
- To vertically scale, we can upgrade our hardware by changing our instance type to handle more compute-intensive, memory-intensive, or storage-intensive workloads. However, since it is not possible to change the hardware specifications on a running EC2 instance, we would need to stop our current instance to implement this, causing some downtime. Also, since EC2 is billed by time, using upgraded hardware could considerably increase the operational cost, especially upfront. While simpler in terms of management, this option may not be as preferable if the increased traffic is not consistently predictable and stable or if we anticipate more extensive scalability in the future.
- To horizontally scale, we can use EC2 Auto Scaling to automatically add or remove EC2 instances based on a selected policy and Elastic Load Balancing to distribute the traffic among the instances. This option is better in terms of scaling incrementally and handling more variable workloads since it allows us to work in a dynamic environment. This option is also likely more cost-effective since we can provision new instances as needed and more fault-tolerant due to the distributed workload. Nonetheless, horizontally scaling does introduce more complexity when considering managing multiple instances, configuring load balancers, and ensuring data consistency.

### DynamoDB
- To scale DynamoDB, we can explore options such as Auto Scaling to automatically scale read and write capacities up and down as needed, partition keys with high cardinality to evenly distribute the workload and avoid hot spots, global secondary indexes for queries, and potentially data sharding to distribute the workload across multiple tables and avoid the limitations of a single table. We can also explore data archiving and time to live to automatically delete expired data for rocket launches that have passed and keep launches that are still active to reduce storage costs, prevent unnecessary scraping, and improve query performance.

### Lambda
- For each concurrent request, Lambda has a separate instance of the execution environment and automatically handles scaling that number up to the concurrency limit. We can explore options for provisioned concurrency due to our scheduled and predictable workload and to help reduce cold start times. This helps keep some instances warm and ready to respond to requests.

### Web Scraper
- To scrape a large number of web pages with high performance, we can use Scrapy instead of Beautiful Soup. We originally chose Beautiful Soup for its simplicity in parsing HTML and XML documents, but we can migrate our logic to Scapy. Scrapy is a full-fledged web scraping framework that has built-in support for asynchronous processing for concurrent requests, following links, handling cookies, rotating proxies to distribute requests across multiple IP addresses, throttling, retry logic, and exporting data to formats like CSV and JSON, among others.
